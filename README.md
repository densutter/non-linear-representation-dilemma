# The Non-Linear Representation Dilemma: Is Causal Abstraction Enough for Mechanistic Interpretability?

Note that the distributed alignment search (DAS) implemented in this repository is a reimplementation of the DAS proposed in "Finding Alignments Between Interpretable Causal Variables and Distributed Neural Representations" (Geiger et al., 2024b). 

The required libraries can be imported with:
```
pip install -r requirements.txt
```

To reproduce our experiments, you must first generate the results for the [Hierarchical Equality and Distributive Law Setting Experiments](#hierarchical-equality-and-distributive-law-setting-experiments) and [Indirect Object Identification Experiments](#indirect-object-identification-experiments-in-run-scripts-folders), then run the plotting functions ([Plot Generation](#plot-generation))

## Reproducing Results

### Hierarchical Equality and Distributive Law Setting Experiments 
The notebooks (in ``notebook`` folder) used for this settings are:

+ [Standard\_DAS.ipynb](notebook/Standard_DAS.ipynb): Notebook used to create the results applying the standard DAS approach as proposed in paper "Finding Alignments Between Interpretable Causal Variables and Distributed Neural Representations" (Geiger et al., 2024b)
+ [Standard\_DAS\_DAS\_fitted.ipynb](notebook/Standard_DAS_DAS_fitted.ipynb): Similar to "Standard\_DAS.ipynb" but MLP model is not only trained to predict the task output but is further biased to ether the And-Or-And or And-Or Algorithm in the Distributive Law Setting.
+ [Hidden\_Size\_Progression.ipynb](notebook/Hidden_Size_Progression.ipynb): Notebook used to create the results applying DAS using different RevNets with different sized hidden layer size.
+ [Training\_Progression.ipynb](notebook/Training_Progression.ipynb): Notebook used to create the results of DAS along the training of the MLP
+ [Standard\_DAS\_Neurons.ipynb](notebook/Standard_DAS_Neurons.ipynb): Notebook used to create the results when instead of applying DAS, using greedy search over the neurons for interventions.

Note that to evaluate the different algorithms (with corresponding Tasks) and bijective function ϕ, the setting has to be manually changed in the notebook. Where and how is indicated with comments and can be easily be done. Note that we provide also a zip file including all results generated by our experiments in these two settings as "Results.zip".

To run the plotting scripts, you must first put the results manually into the following folder structure.
Note: All leaf directories in the structure below contain `result.json` files, except for the subdirectories within `HiddenSizeProgression`. These subdirectories each contain `results_1.json` and `results_2.json`, as we split the hidden sizes into two groups - the first half generates `results_1.json` and the second half generates `results_2.json`. Comments in the notebook explain how to adapt the configurations to generate each file.

```markdown
Results_Cleaned/
├── HiddenSizeProgression/
│   ├── AndOr/
│   ├── AndOrAnd/
│   ├── Both_Equality_Relations/
│   ├── Identity_of_First_Argument/
│   └── Left_Equality_Relation/
├── Standard_DAS/
│   ├── Greedy_Neuronset/
│   │   └── FullyTrained/
│   │       ├── AndOr/
│   │       ├── AndOrAnd/
│   │       ├── Both_Equality_Relations/
│   │       ├── Identity_of_First_Argument/
│   │       └── Left_Equality_Relation/
│   ├── RevNet/
│   │   ├── AndOrAndFix/
│   │   │   ├── AndOr/
│   │   │   └── AndOrAnd/
│   │   ├── AndOrFix/
│   │   │   ├── AndOr/
│   │   │   └── AndOrAnd/
│   │   └── FullyTrained/
│   │       ├── AndOr/
│   │       ├── AndOrAnd/
│   │       ├── Both_Equality_Relations/
│   │       ├── Identity_of_First_Argument/
│   │       └── Left_Equality_Relation/
│   └── Rotation/
│       ├── AndOrAndFix/
│       │   ├── AndOr/
│       │   └── AndOrAnd/
│       ├── AndOrFix/
│       │   ├── AndOr/
│       │   └── AndOrAnd/
│       └── FullyTrained/
│           ├── AndOr/
│           ├── AndOrAnd/
│           ├── Both_Equality_Relations/
│           ├── Identity_of_First_Argument/
│           └── Left_Equality_Relation/
└── TrainingProgression/
    ├── L10HS128/
    │   ├── AndOr/
    │   ├── AndOrAnd/
    │   ├── Both_Equality_Relations/
    │   ├── Identity_of_First_Argument/
    │   └── Left_Equality_Relation/
    ├── L10HS16-24/
    │   ├── AndOr/
    │   ├── AndOrAnd/
    │   ├── Both_Equality_Relations/
    │   ├── Identity_of_First_Argument/
    │   └── Left_Equality_Relation/
    ├── L1HS16-24/
    │   ├── AndOr/
    │   ├── AndOrAnd/
    │   ├── Both_Equality_Relations/
    │   ├── Identity_of_First_Argument/
    │   └── Left_Equality_Relation/
    ├── L5HS16-24/
    │   ├── AndOr/
    │   ├── AndOrAnd/
    │   ├── Both_Equality_Relations/
    │   ├── Identity_of_First_Argument/
    │   └── Left_Equality_Relation/
    └── Rotation/
        ├── AndOr/
        ├── AndOrAnd/
        ├── Both_Equality_Relations/
        ├── Identity_of_First_Argument/
        └── Left_Equality_Relation/
```




### Indirect Object Identification Experiments 
The main training code for DAS on the Pythia suite is implemented in [`scripts/das_llm.py`](scripts/das_llm.py). To reproduce our Pythia experiments, we provide several bash scripts in the `run` folder:

For training progression experiments on Pythia-410M, run:
```bash
bash run/pythia410m.sh
```

For the different pythia sizes experiments, run:
```bash
bash run/pythia_size.sh
```

For the different seeds on pythia410m, run:
```bash
bash run/pythia_seeds.sh
```

These scripts will populate the ``results`` folder with the outputs. Once the results are generated, you can proceed to run the plotting scripts to visualize the data.

## Plot Generation

The plotting scripts automatically generate all plots from the paper and export them to the ``notebooks/plots`` folder.

```bash
# Hierarchical Equality and Distributive Law Setting Experiments 
python notebooks/plot_mlp_hidden_size.py # Hidden Size plots for all MLP experiments
python notebooks/plot_mlp_training_progression.py # Training progression plot for all MLP experiments
# IOI Experiments
python notebooks/plot_pythia410m.py # Training progression plot for pythia 410m
python notebooks/plot_pythiasizes.py # Plot for multiple pythia sizes
python notebooks/plot_pythia410m_seeds.py # Plot for multiple 410m seeds
```
## DAS Library Overview

The ``das`` folder contains the main code for our experiments: 
+ [DAS.py](das/DAS.py): Includes the code for the general DAS class facilitating the DAS experiments
+ [DAS_MLP.py](das/DAS_MLP.py): Includes specific code of the DAS class applied on a MLP.
+ [DAS_LLM.py](das/DAS_LLM.py): Includes specific code of the DAS class applied on a LLM.
+ [Dataset_Generation.py](das/Dataset_Generation.py): Code used for generating the used datasets.
+ [Helper_Functions.py](das/Helper_Functions.py): General helper code
+ [Classification_Model.py](das/Classification_Model.py): Includes the code for the MLP model used for the tasks Hierarchical Equality and Distributed Law Setting Experiments.
+ [LLM_Model.py](das/LLM_Model.py): Code required to get the LLM model used for the Indirect Object Identification Task
+ [Rotation_Model.py](das/Rotation_Model.py): Rotation and its inverse
+ [RevNet.py](das/RevNet.py): RevNet and its inverse
+ [plotting.py](das/plotting.py): Plotting utilities.
