{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f9c7a74-0fa0-4744-819a-12619cec2503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e5e9d24-6909-4640-85be-b28cf9acf426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dummy/dummy/runs/vv4w56dx?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x73910cb96ba0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(mode=\"disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbe41830-b8b7-4508-9d85-91d44912ab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from das.Classification_Model import (MLPForClassification,\n",
    "                                  train_model,\n",
    "                                  eval_model,\n",
    "                                  test_model)\n",
    "from das.Helper_Functions import set_seed\n",
    "from das.Dataset_Generation import (make_model_dataset,\n",
    "                                make_model_dataset_AndOrAnd,\n",
    "                                make_intervention_dataset_variable_intervention_all,\n",
    "                                make_intervention_dataset_variable_intervention_first,\n",
    "                                make_intervention_dataset_first_input_intervention,\n",
    "                                make_intervention_dataset_AndOrAnd,\n",
    "                                make_intervention_dataset_AndOr)\n",
    "from das.RevNet import RevNet\n",
    "from das.Rotation_Model import Rotation\n",
    "from das.DAS import phi_class\n",
    "from das.DAS_MLP import Distributed_Alignment_Search_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25ee9ea0-a20f-4799-91f9-ed529a4865a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE  = \"cpu\" #\"cuda\"/\"cpu\"\n",
    "Setting = \"Both Equality Relations\"\n",
    "#Setting = \"Left Equality Relation\"\n",
    "#Setting = \"Identity of First Argument\"\n",
    "#Setting = \"AndOrAnd\"\n",
    "#Setting = \"AndOr\"\n",
    "\n",
    "\"\"\"\n",
    "transformation_config = {\"type\"        : \"Rotation\",\n",
    "                         \"in_features\" :         24}\n",
    "\"\"\"\n",
    "transformation_config = {\"type\"          : \"RevNet\",\n",
    "                         \"number_blocks\" :        1,\n",
    "                         \"in_features\"   :       16,\n",
    "                         \"hidden_size\"   :       16}\n",
    "\n",
    "Max_Epochs                       = 50\n",
    "Early_Stopping_Epochs            = 5\n",
    "early_stopping_improve_threshold = 0.001\n",
    "ReduceLROnPlateau_patience       = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0ad5206-60ed-42f8-be85-1f3eca8cd806",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_variable_settings = [\"Identity of First Argument\"]\n",
    "two_variable_settings = [\"Both Equality Relations\",\"Left Equality Relation\",\"AndOrAnd\",\"AndOr\"]\n",
    "DAS_Original_tasks    = [\"Both Equality Relations\",\"Left Equality Relation\",\"Identity of First Argument\"]\n",
    "AndOrAnd_tasks        = [\"AndOrAnd\",\"AndOr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "089066ea-6bbc-4666-bcba-a70b0ce8f4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef make_test_intervened_input_DS(DS):\\n    DS_X=[]\\n    DS_y=[]\\n    for a_DS in DS:\\n        DS_y.append(a_DS[\"label\"])\\n        DS_X.append(copy.deepcopy(a_DS[\"base\"]))\\n        for i in range(2):\\n            if a_DS[\"intervention\"][i]:\\n                DS_X[-1][8*i:8*(i+1)]=copy.deepcopy(a_DS[\"sources\"][i])[8*i:8*(i+1)]\\n    return DS_X,DS_y\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Helper Functions:\n",
    "\n",
    "def chunk_list(input_list, batch_size):\n",
    "    return [input_list[i:i + batch_size] for i in range(0, len(input_list), batch_size)]\n",
    "\n",
    "# Removed as this is not possible for all task. \n",
    "# Further DAS compares its performance with the general performance so I decided to use a standard test set \n",
    "# rather than one which is made out of \"intervened inputs\"\n",
    "\"\"\"\n",
    "def make_test_intervened_input_DS(DS):\n",
    "    DS_X=[]\n",
    "    DS_y=[]\n",
    "    for a_DS in DS:\n",
    "        DS_y.append(a_DS[\"label\"])\n",
    "        DS_X.append(copy.deepcopy(a_DS[\"base\"]))\n",
    "        for i in range(2):\n",
    "            if a_DS[\"intervention\"][i]:\n",
    "                DS_X[-1][8*i:8*(i+1)]=copy.deepcopy(a_DS[\"sources\"][i])[8*i:8*(i+1)]\n",
    "    return DS_X,DS_y\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e98d55-7e8a-4dec-872c-7b6b1ca6a144",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/master/DAS/github/Complexity-vs.-Accuracy/notebooks/../das/Dataset_Generation.py:64: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  return torch.tensor(model_inputs, dtype=torch.float32).to(device),torch.tensor(labels, dtype=torch.float32).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer1 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.6982,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3917\n",
      "Layer1 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.6991,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3945\n",
      "Layer1 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.6989,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3943\n",
      "Layer2 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.6991,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3942\n",
      "Layer2 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.6992,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3975\n",
      "Layer2 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.6988,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3939\n",
      "Layer3 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.6992,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3981\n",
      "Layer3 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.6992,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3982\n",
      "Layer3 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.6992,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3982\n",
      "Layer1 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.6932,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3864\n",
      "Layer1 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.6932,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3864\n",
      "Layer1 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.6932,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3866\n",
      "Layer2 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.6932,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3864\n",
      "Layer2 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.6932,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3866\n",
      "Layer2 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.6932,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3866\n",
      "Layer3 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.6932,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3864\n",
      "Layer3 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.6932,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3867\n",
      "Layer3 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.6932,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3866\n",
      "Layer1 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.6925,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3833\n",
      "Layer1 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.6931,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3860\n",
      "Layer1 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.6934,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3869\n",
      "Layer2 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.6931,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3858\n",
      "Layer2 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.6933,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3865\n",
      "Layer2 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.6933,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3864\n",
      "Layer3 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.6933,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3863\n",
      "Layer3 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.6933,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3867\n",
      "Layer3 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.6933,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3869\n",
      "Layer1 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.6901,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3597\n",
      "Layer1 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.6955,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3890\n",
      "Layer1 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.6964,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3867\n",
      "Layer2 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.6944,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3823\n",
      "Layer2 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.6963,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3881\n",
      "Layer2 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.6966,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3897\n",
      "Layer3 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.6947,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3820\n",
      "Layer3 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.6958,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3879\n",
      "Layer3 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.6967,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3897\n",
      "Layer1 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.6915,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3469\n",
      "Layer1 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.7047,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3850\n",
      "Layer1 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.7165,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.4051\n",
      "Layer2 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.7027,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3795\n",
      "Layer2 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.7088,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3829\n",
      "Layer2 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.7110,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.4053\n",
      "Layer3 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.6978,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3655\n",
      "Layer3 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.7022,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3649\n",
      "Layer3 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.7097,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3995\n",
      "Layer1 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.7085,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.2966\n",
      "Layer1 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.7448,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.4087\n",
      "Layer1 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.7620,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.4280\n",
      "Layer2 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.7432,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.4294\n",
      "Layer2 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.7537,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.4509\n",
      "Layer2 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.7620,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.4690\n",
      "Layer3 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.7381,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.4216\n",
      "Layer3 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.7321,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3843\n",
      "Layer3 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.7512,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.4589\n",
      "Layer1 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.7068,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.0596\n",
      "Layer1 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.7770,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3052\n",
      "Layer1 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.8458,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.4970\n",
      "Layer2 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.8071,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3974\n",
      "Layer2 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.8180,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.4982\n",
      "Layer2 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.8447,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.5397\n",
      "Layer3 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.7932,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.4558\n",
      "Layer3 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.8128,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.5212\n",
      "Layer3 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.8156,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.5038\n",
      "Layer1 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.7524,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.2366\n",
      "Layer1 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.8231,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.2089\n",
      "Layer1 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 1.0124,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.7430\n",
      "Layer2 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.9030,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.5083\n",
      "Layer2 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.9488,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.6217\n",
      "Layer2 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 1.0054,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.7104\n",
      "Layer3 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.8302,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.4301\n",
      "Layer3 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.9135,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.5705\n",
      "Layer3 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.9505,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.6407\n",
      "Layer1 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.8916,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.2322\n",
      "Layer1 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 1.0157,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.4207\n",
      "Layer1 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 1.2223,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.1346\n",
      "Layer2 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 1.0533,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.6513\n",
      "Layer2 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 1.2696,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.0511\n",
      "Layer2 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 1.2603,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.1203\n",
      "Layer3 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 1.0381,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.7931\n",
      "Layer3 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 1.0339,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.6396\n",
      "Layer3 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 1.0794,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.8150\n",
      "Layer1 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.9408,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 0.8997\n",
      "Layer1 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 1.2303,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.5769\n",
      "Layer1 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 1.4787,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.3197\n",
      "Layer2 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 1.2747,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.2542\n",
      "Layer2 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 1.4217,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.9846\n",
      "Layer2 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 1.5414,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.4713\n",
      "Layer3 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 1.1788,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.8976\n",
      "Layer3 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 1.3337,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.2238\n",
      "Layer3 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 1.3577,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.1904\n",
      "Layer1 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 1.2089,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.4491\n",
      "Layer1 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 1.5002,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.8392\n",
      "Layer1 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 1.9257,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 3.3797\n",
      "Layer2 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 1.6744,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.5662\n",
      "Layer2 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 1.7786,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.5384\n",
      "Layer2 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 1.9965,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 3.4529\n",
      "Layer3 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 1.4569,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.0691\n",
      "Layer3 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 1.4995,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.1788\n",
      "Layer3 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 1.5881,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.2259\n",
      "Layer1 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 1.2870,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.4328\n",
      "Layer1 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 1.7614,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.2387\n",
      "Layer1 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 2.3723,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 4.0876\n",
      "Layer2 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 1.4953,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.1291\n",
      "Layer2 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 2.0926,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.9095\n",
      "Layer2 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 2.3127,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 3.5908\n",
      "Layer3 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 1.4777,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.7561\n",
      "Layer3 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 1.7480,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.1728\n",
      "Layer3 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 1.9488,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.5129\n",
      "Layer1 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 1.4043,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3111\n",
      "Layer1 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 2.0540,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.6200\n",
      "Layer1 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 2.6782,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 4.4777\n",
      "Layer2 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 2.6769,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 3.4337\n",
      "Layer2 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 2.4568,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 3.3039\n",
      "Layer2 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 2.6615,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 3.8947\n",
      "Layer3 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 1.8111,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.1885\n",
      "Layer3 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 2.0809,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.2072\n",
      "Layer3 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 2.3034,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.9834\n",
      "Layer1 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 1.4880,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 0.8611\n",
      "Layer1 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 2.5637,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 3.0512\n",
      "Layer1 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 3.2583,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 5.0646\n",
      "Layer2 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 3.0848,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 3.7896\n",
      "Layer2 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 2.8186,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 3.2643\n",
      "Layer2 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 2.8984,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 4.6428\n",
      "Layer3 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 1.9250,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.1255\n",
      "Layer3 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 2.2231,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.1188\n",
      "Layer3 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 2.3738,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.9550\n",
      "Layer1 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 2.0741,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.6614\n",
      "Layer1 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 2.5540,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.7040\n",
      "Layer1 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 3.6698,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 5.9208\n",
      "Layer2 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 2.0941,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.1955\n",
      "Layer2 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 3.1103,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 3.8985\n",
      "Layer2 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 3.1578,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 3.8074\n",
      "Layer3 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 2.3771,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.2933\n",
      "Layer3 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 2.5706,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.3590\n",
      "Layer3 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 2.6571,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.8278\n",
      "Layer1 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 1.9434,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.5278\n",
      "Layer1 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 2.8744,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 3.2492\n",
      "Layer1 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 4.1584,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 6.6036\n",
      "Layer2 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 2.5982,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.3137\n",
      "Layer2 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 3.4931,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 5.3690\n",
      "Layer2 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 3.6158,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 4.4217\n",
      "Layer3 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 2.5173,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.8966\n",
      "Layer3 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 2.9579,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.6005\n",
      "Layer3 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 2.9353,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.8441\n",
      "Layer1 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 2.4765,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.6080\n",
      "Layer1 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 3.1608,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 3.1020\n",
      "Layer1 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 4.2320,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 6.5061\n",
      "Layer2 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 4.0784,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 4.2907\n",
      "Layer2 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 3.5173,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 3.1393\n",
      "Layer2 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 3.6251,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 3.7630\n",
      "Layer3 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 2.5283,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 2.7366\n",
      "Layer3 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 3.0731,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 3.2913\n",
      "Layer3 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 3.2233,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 3.2098\n",
      "Layer1 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.6944,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3886\n",
      "Layer1 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.6947,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3902\n",
      "Layer1 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.6947,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3894\n",
      "Layer2 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.6947,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3903\n",
      "Layer2 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.6947,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3899\n",
      "Layer2 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.6947,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3902\n",
      "Layer3 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.6947,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3902\n",
      "Layer3 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.6947,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3902\n",
      "Layer3 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.6947,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3902\n",
      "Layer1 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.6932,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3865\n",
      "Layer1 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.6932,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3864\n",
      "Layer1 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.6932,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3864\n",
      "Layer2 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.6932,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3866\n",
      "Layer2 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.6932,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3864\n",
      "Layer2 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.6932,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3864\n",
      "Layer3 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.6932,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3864\n",
      "Layer3 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.6932,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3864\n",
      "Layer3 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.6932,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3864\n",
      "Layer1 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.6932,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3864\n",
      "Layer1 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.6932,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3859\n",
      "Layer1 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.6934,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3863\n",
      "Layer2 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.6933,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3866\n",
      "Layer2 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.6933,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3863\n",
      "Layer2 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.6934,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3865\n",
      "Layer3 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.6933,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3865\n",
      "Layer3 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.6933,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3864\n",
      "Layer3 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.6933,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3864\n",
      "Layer1 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.6980,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3929\n",
      "Layer1 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.6994,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3938\n",
      "Layer1 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.7018,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3998\n",
      "Layer2 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.6979,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3927\n",
      "Layer2 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.6985,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3946\n",
      "Layer2 : [[0], [1]]\n",
      "Epoch 1, Avg Loss: 0.6996,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3954\n",
      "Layer3 : [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "Epoch 1, Avg Loss: 0.6978,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3945\n",
      "Layer3 : [[0, 1], [2, 3]]\n",
      "Epoch 1, Avg Loss: 0.6989,  Steps w/o Improvement: 0,  Eval Loss (End of Epoch): inf , LR for next epoch (base): 0.001\n",
      "Loading best phi with loss: 1.3930\n",
      "Layer3 : [[0], [1]]\n"
     ]
    }
   ],
   "source": [
    "#DAS Training Loop\n",
    "\n",
    "results=[]\n",
    "for acseed in [4287, 3837, 9097, 2635, 5137, 6442, 5234, 4641, 8039, 2266]:\n",
    "    set_seed(acseed)\n",
    "    model = MLPForClassification(input_size=transformation_config[\"in_features\"])\n",
    "    model.to(DEVICE)\n",
    "    if Setting in DAS_Original_tasks:\n",
    "        X_train,y_train = make_model_dataset(1048576,4,DEVICE)\n",
    "        X_eval,y_eval   = make_model_dataset(10000,4,DEVICE)\n",
    "        X_test,y_test   = make_model_dataset(10000,4,DEVICE)\n",
    "    elif Setting in AndOrAnd_tasks:\n",
    "        X_train,y_train = make_model_dataset_AndOrAnd(1048576,4,DEVICE)\n",
    "        X_eval,y_eval   = make_model_dataset_AndOrAnd(10000,4,DEVICE)\n",
    "        X_test,y_test   = make_model_dataset_AndOrAnd(10000,4,DEVICE)\n",
    "        \n",
    "\n",
    "    indexes=[None]\n",
    "    indexes_num=list(range(X_train.shape[0]))\n",
    "    random.shuffle(indexes_num)\n",
    "    indexes+=chunk_list(indexes_num, 1048576//8)\n",
    "    random.shuffle(indexes_num)\n",
    "    indexes+=chunk_list(indexes_num, 1048576//8)\n",
    "    \"\"\"\n",
    "    random.shuffle(indexes_num)\n",
    "    indexes+=chunk_list(indexes_num, 1048576//4)\n",
    "    random.shuffle(indexes_num)\n",
    "    indexes+=chunk_list(indexes_num, 1048576//4)\n",
    "    random.shuffle(indexes_num)\n",
    "    indexes+=chunk_list(indexes_num, 1048576//4)#//20)#5 epochs each epoch split into 16 steps\n",
    "    \"\"\"\n",
    "    \n",
    "    Layers=[]\n",
    "    Layers.append((\"Layer1\",model.mlp.h[0]))\n",
    "    Layers.append((\"Layer2\",model.mlp.h[1]))\n",
    "    Layers.append((\"Layer3\",model.mlp.h[2]))\n",
    "    inter_dims=[]\n",
    "\n",
    "    if Setting in two_variable_settings:\n",
    "        inter_dims.append([list(range(0,transformation_config[\"in_features\"]//2)),list(range(transformation_config[\"in_features\"]//2,transformation_config[\"in_features\"]))])\n",
    "        inter_dims.append([list(range(0,2)),list(range(2,4))])\n",
    "        inter_dims.append([list(range(0,1)),list(range(1,2))])\n",
    "    elif Setting in one_variable_settings:\n",
    "        inter_dims.append([list(range(0,transformation_config[\"in_features\"]//2))])\n",
    "        inter_dims.append([list(range(0,2))])\n",
    "        inter_dims.append([list(range(0,1))])\n",
    "    else:\n",
    "        Exception(\"Unknown Setting\")\n",
    "\n",
    "    if Setting == \"Both Equality Relations\":\n",
    "        DAS_Train = make_intervention_dataset_variable_intervention_all(1280000,4)\n",
    "        DAS_Test  = make_intervention_dataset_variable_intervention_all(10000,4)\n",
    "        DAS_Eval  = make_intervention_dataset_variable_intervention_all(10000,4)\n",
    "    elif Setting == \"Left Equality Relation\":\n",
    "        DAS_Train = make_intervention_dataset_variable_intervention_first(1280000,4)\n",
    "        DAS_Test  = make_intervention_dataset_variable_intervention_first(10000,4)\n",
    "        DAS_Eval  = make_intervention_dataset_variable_intervention_first(10000,4)\n",
    "    elif Setting == \"Identity of First Argument\":\n",
    "        DAS_Train = make_intervention_dataset_first_input_intervention(1280000,4)\n",
    "        DAS_Test  = make_intervention_dataset_first_input_intervention(10000,4)\n",
    "        DAS_Eval  = make_intervention_dataset_first_input_intervention(10000,4)\n",
    "    elif Setting == \"AndOrAnd\":\n",
    "        DAS_Train = make_intervention_dataset_AndOrAnd(1280000,4)\n",
    "        DAS_Test  = make_intervention_dataset_AndOrAnd(10000,4)\n",
    "        DAS_Eval  = make_intervention_dataset_AndOrAnd(10000,4)\n",
    "    elif Setting == \"AndOr\":\n",
    "        DAS_Train = make_intervention_dataset_AndOr(1280000,4)\n",
    "        DAS_Test  = make_intervention_dataset_AndOr(10000,4)\n",
    "        DAS_Eval  = make_intervention_dataset_AndOr(10000,4)\n",
    "    else:\n",
    "        Exception(\"Unknown Setting\")\n",
    "\n",
    "    # Not used anymore see explanation above:\n",
    "    #X_test,y_test=make_test_intervened_input_DS(DAS_Test)\n",
    "    #X_test=torch.stack(X_test).to(DEVICE)\n",
    "    #y_test=torch.stack(y_test).to(DEVICE)\n",
    "    results.append([])\n",
    "    for ac_in in indexes:   \n",
    "        results[-1].append({})\n",
    "        model.train()\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True  # This unfreezes the weights\n",
    "        if ac_in is not None:# first DAS on untrained\n",
    "            model=train_model(model,X_train[ac_in],y_train[ac_in],X_eval,y_eval,batch_size = 1024,epochs=1)\n",
    "        accuracy=test_model(model,X_test,y_test)\n",
    "        \n",
    "        results[-1][-1][\"accuracy\"]=accuracy\n",
    "        for LayerName,Layer in Layers:\n",
    "            results[-1][-1][LayerName]={}\n",
    "            for inter_dim in inter_dims:\n",
    "                print(LayerName,\":\",inter_dim, flush=True)\n",
    "        \n",
    "                #Initialize transformation function\n",
    "                if transformation_config[\"type\"]==\"Rotation\":\n",
    "                    p = Rotation(transformation_config[\"in_features\"])\n",
    "                elif transformation_config[\"type\"]==\"RevNet\":\n",
    "                    p = RevNet(number_blocks =  transformation_config[\"number_blocks\"],\n",
    "                               in_features   =  transformation_config[\"in_features\"],\n",
    "                               hidden_size   =  transformation_config[\"hidden_size\"]\n",
    "                              )\n",
    "                else:\n",
    "                    Exception(\"Unknown transformation function\")\n",
    "                p.to(DEVICE)\n",
    "                p_inverse = p.inverse\n",
    "                optimizer = optim.Adam(p.parameters(), lr=0.001)\n",
    "                scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=ReduceLROnPlateau_patience)\n",
    "                criterion = nn.CrossEntropyLoss()\n",
    "                phi=phi_class(p,p_inverse,criterion,optimizer,scheduler)\n",
    "        \n",
    "                \n",
    "        \n",
    "                DAS_Experiment=Distributed_Alignment_Search_MLP(Model                = model,\n",
    "                                                                Model_Layer          = Layer,\n",
    "                                                                Train_Data_Raw       = DAS_Train,\n",
    "                                                                Test_Data_Raw        = DAS_Test,\n",
    "                                                                Eval_Data_Raw        = DAS_Eval,\n",
    "                                                                Hidden_Layer_Size    = transformation_config[\"in_features\"],\n",
    "                                                                Variable_Dimensions  = inter_dim,\n",
    "                                                                Transformation_Class = phi,\n",
    "                                                                Device               = DEVICE)\n",
    "        \n",
    "                DAS_Experiment.train_test(batch_size=6400,\n",
    "                                          epochs=Max_Epochs,\n",
    "                                          mode=1,\n",
    "                                          early_stopping_threshold=Early_Stopping_Epochs,\n",
    "                                          early_stopping_improve_threshold=early_stopping_improve_threshold) #Train\n",
    "        \n",
    "                accuracy=DAS_Experiment.train_test(batch_size=6400,\n",
    "                                                   mode=2)\n",
    "                \n",
    "                results[-1][-1][LayerName][str(inter_dim)]=accuracy\n",
    "                DAS_Experiment.Cleanup()\n",
    "                DAS_Experiment=None\n",
    "                with open('results.json', 'w') as f:\n",
    "                    json.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
