{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f9c7a74-0fa0-4744-819a-12619cec2503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "device=\"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81a91f40-f788-435e-86e8-6be14fdf17ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the random seeds\n",
    "\n",
    "def set_seed(seed):\n",
    "    # Set the seed for the random module\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Set the seed for numpy\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Set the seed for PyTorch (CPU)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    # Set the seed for PyTorch (GPU) if you are using CUDA\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # For multi-GPU setups\n",
    "    \n",
    "    # Ensure deterministic behavior in PyTorch\n",
    "    torch.backends.cudnn.deterministic = True  # This makes the computations deterministic\n",
    "    torch.backends.cudnn.benchmark = False  # Disable auto-tuning for performance optimization\n",
    "    \n",
    "    # For reproducibility of other libraries like Python's `random`\n",
    "    torch.random.manual_seed(seed)\n",
    "\n",
    "# Set the seed\n",
    "set_seed(53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "247c1827-904c-4d9b-891e-27185f62dde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPForClassification(\n",
       "  (mlp): MLPModel(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-2): 3 x MLPBlock(\n",
       "        (ff1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (act): ReLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (score): Linear(in_features=16, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classification model\n",
    "\n",
    "class MLPBlock(nn.Module):\n",
    "    def __init__(self, in_features=16, out_features=16, dropout_prob=0.0):\n",
    "        super(MLPBlock, self).__init__()\n",
    "        self.ff1 = nn.Linear(in_features, out_features)\n",
    "        self.act = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ff1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_size=16, hidden_size=16, num_blocks=3, dropout_prob=0.0):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        self.h = nn.ModuleList([MLPBlock(hidden_size, hidden_size, dropout_prob) for _ in range(num_blocks)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        for layer in self.h:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "class MLPForClassification(nn.Module):\n",
    "    def __init__(self, input_size=16, hidden_size=16, num_classes=2, num_blocks=3, dropout_prob=0.0):\n",
    "        super(MLPForClassification, self).__init__()\n",
    "        self.mlp = MLPModel(input_size, hidden_size, num_blocks, dropout_prob)\n",
    "        self.score = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mlp(x)\n",
    "        x = self.score(x)\n",
    "        return x\n",
    "\n",
    "model = MLPForClassification()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3648a88-495f-47cb-8889-5e8ea1a07958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1024/1024 [00:09<00:00, 106.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.34166701680078404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1024/1024 [00:09<00:00, 109.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.018978380689986807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1024/1024 [00:09<00:00, 109.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.004886364653827968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training of the classification model\n",
    "\n",
    "# Load Training Dataset:\n",
    "# Load preprocessed training features (X_train) and labels (y_train) from pickle files\n",
    "with open(\"X_train.pkl\", \"rb\") as f:\n",
    "    X_train = pickle.load(f)\n",
    "\n",
    "with open(\"y_train.pkl\", \"rb\") as f:\n",
    "    y_train = pickle.load(f)\n",
    "\n",
    "# Move data to the specified device (CPU/GPU) for training\n",
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "\n",
    "# Create DataLoader:\n",
    "batch_size = 1024  # Number of samples per batch\n",
    "epochs = 3  # Number of training iterations over the entire dataset\n",
    "\n",
    "# Create a PyTorch dataset and DataLoader for batch processing\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)  # Shuffle data for better generalization\n",
    "\n",
    "# Initialize model, loss function, and optimizer:\n",
    "criterion = nn.CrossEntropyLoss()  # Loss function for multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer with learning rate of 0.001\n",
    "\n",
    "# Training Loop:\n",
    "model.train()  # Set model to training mode\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0  # Track total loss for the epoch\n",
    "\n",
    "    # Iterate over training batches\n",
    "    for X_batch, y_batch in tqdm(train_loader):  \n",
    "        optimizer.zero_grad()  # Reset gradients before each batch\n",
    "        \n",
    "        outputs = model(X_batch)  # Forward pass: compute model predictions\n",
    "        loss = criterion(outputs, y_batch.squeeze().long())  # Compute loss\n",
    "\n",
    "        loss.backward()  # Backpropagation: compute gradients\n",
    "        optimizer.step()  # Update model parameters\n",
    "\n",
    "        total_loss += loss.item()  # Accumulate loss\n",
    "\n",
    "    # Print average loss for the epoch\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c168250-1742-4c61-9ca4-33b737b4634c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 90.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing the Classification Model:\n",
    "\n",
    "# Load Testing Dataset:\n",
    "# Load preprocessed testing features (X_test) and labels (y_test) from pickle files\n",
    "with open(\"X_test.pkl\", \"rb\") as f:\n",
    "    X_test = pickle.load(f)\n",
    "\n",
    "with open(\"y_test.pkl\", \"rb\") as f:\n",
    "    y_test = pickle.load(f)\n",
    "\n",
    "# Move test data to the specified device (CPU/GPU)\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "# Create DataLoader:\n",
    "# Create a PyTorch dataset and DataLoader for batch processing during testing\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)  # No shuffling needed for evaluation\n",
    "\n",
    "# Evaluate Model:\n",
    "model.eval()  # Set model to evaluation mode (disables dropout, batch norm updates)\n",
    "\n",
    "correct = 0  # Track the number of correct predictions\n",
    "total = 0  # Track the total number of samples\n",
    "\n",
    "# Disable gradient calculation to speed up inference and reduce memory usage\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in tqdm(test_loader):\n",
    "        outputs = model(X_batch)  # Forward pass: compute model predictions\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)  # Get the class with the highest probability\n",
    "        correct += (predicted == y_batch.squeeze()).sum().item()  # Count correct predictions\n",
    "        total += y_batch.size(0)  # Update total sample count\n",
    "\n",
    "# Compute and display test accuracy\n",
    "accuracy = correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fe7a0cf-9782-425e-8c81-4238c791648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the transformation model\n",
    "# This transformation is referred to as \"phi\" in our current paper \n",
    "# and as \"rotation\" in the original DAS paper.\n",
    "# At this stage, it is simply a rotation matrix.\n",
    "\n",
    "# The RotateLayer class is copied directly from the DAS library.\n",
    "\n",
    "class RotateLayer(torch.nn.Module):\n",
    "    \"\"\"A learnable linear transformation initialized as an orthogonal matrix.\"\"\"\n",
    "\n",
    "    def __init__(self, n, init_orth=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n (int): Dimension of the square transformation matrix.\n",
    "            init_orth (bool): If True, initializes the matrix with an orthogonal weight.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        weight = torch.empty(n, n)  # Create an empty n x n matrix\n",
    "        \n",
    "        # We don't need initialization if loading from a pretrained checkpoint.\n",
    "        # You can explore different initialization strategies if necessary, but this isn't our focus.\n",
    "        if init_orth:\n",
    "            torch.nn.init.orthogonal_(weight)\n",
    "        \n",
    "        self.weight = torch.nn.Parameter(weight, requires_grad=True)  # Learnable weight matrix\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Applies the rotation matrix to the input tensor.\"\"\"\n",
    "        return torch.matmul(x.to(self.weight.dtype), self.weight)\n",
    "        \n",
    "\n",
    "class Transformation_Function(nn.Module):\n",
    "    \"\"\"Encapsulates the rotation transformation as a PyTorch module.\"\"\"\n",
    "\n",
    "    def __init__(self, embed_dim=16):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embed_dim (int): The embedding dimension (size of the transformation matrix).\n",
    "        \"\"\"\n",
    "        super(Transformation_Function, self).__init__()\n",
    "        \n",
    "        rotate_layer = RotateLayer(embed_dim)  # Initialize the rotation layer\n",
    "        # Ensure the transformation remains an orthogonal matrix\n",
    "        self.rotate_layer = torch.nn.utils.parametrizations.orthogonal(rotate_layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Applies the orthogonal transformation to the input tensor.\"\"\"\n",
    "        return self.rotate_layer(x)\n",
    "\n",
    "\n",
    "class InverseTransformation_Function(nn.Module):\n",
    "    \"\"\"Computes the inverse of the given transformation function (phi).\"\"\"\n",
    "\n",
    "    def __init__(self, transformation_function: Transformation_Function):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            transformation_function (Transformation_Function): The forward transformation function.\n",
    "        \"\"\"\n",
    "        super(InverseTransformation_Function, self).__init__()\n",
    "        self.transformation_function = transformation_function  # Store reference to the transformation\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Applies the inverse transformation by transposing the orthogonal weight matrix.\"\"\"\n",
    "        weight_T = self.transformation_function.rotate_layer.weight.T  # Use matrix transpose as inverse\n",
    "        return torch.matmul(x.to(weight_T.dtype), weight_T)\n",
    "\n",
    "\n",
    "# Instantiate the transformation and its inverse\n",
    "phi = Transformation_Function(16)\n",
    "phi.to(device)  # Move transformation model to the specified device\n",
    "\n",
    "phi_inverse = InverseTransformation_Function(phi)\n",
    "phi_inverse.to(device)  # Move inverse transformation to the device\n",
    "\n",
    "# Define loss function and optimizer for training the transformation function\n",
    "criterion = nn.CrossEntropyLoss()  # Standard loss function for classification\n",
    "optimizer = optim.Adam(phi.parameters(), lr=0.001)  # Adam optimizer for updating phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36a80faf-f8b3-4b8a-a622-fcf595127fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters used for DAS with this classification model\n",
    "\n",
    "activation_dimension = 16  # Dimensionality of the hidden representation in the analyzed model\n",
    "\n",
    "# Mapping of dimensions in the rotated space to specific features\n",
    "# Each list specifies which indices in the transformed feature space correspond to a particular feature.\n",
    "# In this case, the first 8 dimensions (0-7) belong to the first feature,\n",
    "# and the next 8 dimensions (8-15) belong to the second feature.\n",
    "dim_per_feature = [\n",
    "    list(range(0, 8)),   # First feature (uses dimensions 0 to 7)\n",
    "    list(range(8, 16))   # Second feature (uses dimensions 8 to 15)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29a5f52f-4908-4beb-9b7b-8d9bbba7f6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the generated datasets directly from the DAS paper's codebase:\n",
    "# Reference: https://github.com/stanfordnlp/pyvene/blob/main/tutorials/advanced_tutorials/DAS_Main_Introduction.ipynb\n",
    "# See also my second uploaded file. These functions are helper functions \n",
    "# to transform the DAS training and testing datasets into a format usable by my code.\n",
    "\n",
    "def chunk_list(input_list, batch_size):\n",
    "    \"\"\"\n",
    "    Splits a list into smaller chunks of size `batch_size`.\n",
    "    \n",
    "    Args:\n",
    "        input_list (list): The list to be split.\n",
    "        batch_size (int): The size of each chunk.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of batches (sublists).\n",
    "    \"\"\"\n",
    "    return [input_list[i:i + batch_size] for i in range(0, len(input_list), batch_size)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_base(input_list):\n",
    "    \"\"\"\n",
    "    Extracts the `input_ids` from a list of input samples and stacks them into a tensor. (base input)\n",
    "    \n",
    "    Args:\n",
    "        input_list (list): List of dictionary-like objects containing `input_ids`.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A tensor of extracted `input_ids`, moved to the appropriate device.\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for i in input_list:\n",
    "        res.append(i[\"input_ids\"])  # Extract 'input_ids' from each sample\n",
    "\n",
    "    res = torch.stack(res)  # Convert list to tensor\n",
    "    res = res.to(device)  # Move tensor to the designated device\n",
    "    return res\n",
    "\n",
    "def extract_sources(input_list):\n",
    "    \"\"\"\n",
    "    Extracts `source_input_ids` from the dataset. if `intervention_id=1` I need to swap source positions. (source input)\n",
    "    \n",
    "    Args:\n",
    "        input_list (list): List of dictionary-like objects containing `source_input_ids`.\n",
    "\n",
    "    Returns:\n",
    "        list of torch.Tensor: A list of tensors containing grouped `source_input_ids`, moved to device.\n",
    "    \"\"\"\n",
    "    res = [[] for _ in range(input_list[0]['source_input_ids'].shape[0])]  # Initialize list of empty lists\n",
    "\n",
    "    for i in input_list:\n",
    "        for j in range(i['source_input_ids'].shape[0]):\n",
    "            if i['intervention_id'] in [0,2]:\n",
    "                res[j].append(i['source_input_ids'][j])\n",
    "            elif i['intervention_id'] in [1]:\n",
    "                res[1 - j].append(i['source_input_ids'][j])  \n",
    "            else:\n",
    "                print(\"[ERROR]\")\n",
    "                exit()\n",
    "\n",
    "    for i in range(len(res)):  # Convert lists to tensors and move to device\n",
    "        res[i] = torch.stack(res[i])\n",
    "        res[i] = res[i].to(device)\n",
    "\n",
    "    return res\n",
    "\n",
    "def extract_labels(input_list):\n",
    "    \"\"\"\n",
    "    Extracts the expected output labels after intervention from the dataset and \n",
    "    converts them into a stacked tensor.\n",
    "\n",
    "    Args:\n",
    "        input_list (list): A list of dictionary-like objects containing the key \"labels\".\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A tensor of extracted labels, moved to the appropriate device.\n",
    "    \"\"\"\n",
    "    res = []  # Initialize an empty list to store labels\n",
    "\n",
    "    for i in input_list:\n",
    "        res.append(i[\"labels\"])  # Extract the \"labels\" field from each input sample\n",
    "\n",
    "    res = torch.stack(res)  # Convert list of labels into a tensor\n",
    "    res = res.to(device)  # Move tensor to the designated device\n",
    "    return res\n",
    "\n",
    "\n",
    "def prepare_intervention_matrix(input_list): \n",
    "    \"\"\"\n",
    "    Creates an intervention matrix of shape (batch_size, activation_dimension).\n",
    "    \n",
    "    The matrix is a boolean tensor indicating, for each element in each sample in the batch,\n",
    "    whether it should use the base value (False) or the source value (True).\n",
    "    \n",
    "    Args:\n",
    "        input_list (list): A list of dictionary-like objects, each containing an \"intervention_id\".\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: A boolean tensor of shape (batch_size, activation_dimension),\n",
    "                      moved to the appropriate device.\n",
    "    \"\"\"\n",
    "    res = []  # Initialize an empty list to store intervention indicators\n",
    "\n",
    "    for i in input_list:\n",
    "        res.append([])  # Append a new row for each input sample\n",
    "        for j in range(activation_dimension):  # Iterate over all dimensions\n",
    "            if j in dim_per_feature[0]:  # Check if the dimension belongs to the first feature\n",
    "                if i[\"intervention_id\"] in [0, 2]:  \n",
    "                    res[-1].append(True)  # Use source value\n",
    "                else:\n",
    "                    res[-1].append(False)  # Use base value\n",
    "            elif j in dim_per_feature[1]:  # Check if the dimension belongs to the second feature\n",
    "                if i[\"intervention_id\"] in [1, 2]:  \n",
    "                    res[-1].append(True)  # Use source value\n",
    "                else:\n",
    "                    res[-1].append(False)  # Use base value\n",
    "            else:\n",
    "                res[-1].append(False)  # Default to base value for dimensions not explicitly assigned\n",
    "\n",
    "    res = torch.tensor(res)  # Convert list to a PyTorch tensor\n",
    "    res = res.to(device)  # Move tensor to the designated device\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "779d45ea-0b80-402c-a41b-4d5270348fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the hook function responsible for performing interventions on activations.\n",
    "\n",
    "mode_info = None  # Stores mode information (either \"source\" or \"intervene\") and relevant information.\n",
    "source_activations = None  # A tensor of shape (batch_size, activation_dimension).\n",
    "# This tensor stores the rotated activations of the source inputs at the positions where\n",
    "# intervention is supposed to occur in the transformed space.\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    \"\"\"\n",
    "    A forward hook function that performs intervention on activations during forward pass.\n",
    "\n",
    "    Behavior:\n",
    "    - If `mode_info[0]` is \"source\", it stores the rotated activations of the source inputs\n",
    "      in `source_activations` at the designated intervention positions.\n",
    "    - If `mode_info[0]` is \"intervene\", it modifies the activations by replacing base activations\n",
    "      with the stored source activations at the designated positions.\n",
    "\n",
    "    Args:\n",
    "        module (nn.Module): The module where the hook is attached.\n",
    "        input (tuple): The input to the module.\n",
    "        output (torch.Tensor): The output activations from the module.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor (only in \"intervene\" mode): The modified activations with intervention applied.\n",
    "    \"\"\"\n",
    "    global mode_info\n",
    "    global source_activations\n",
    "\n",
    "    if mode_info[0] == \"source\":\n",
    "        # If processing a source input, store its rotated activations in `source_activations`\n",
    "        # but only at the dimensions assigned to the specified feature (mode_info[1]).\n",
    "        source_activations[:, dim_per_feature[mode_info[1]]] = phi(output.detach())[:, dim_per_feature[mode_info[1]]]\n",
    "\n",
    "    elif mode_info[0] == \"intervene\":\n",
    "        # Get the rotated activations of the base input\n",
    "        result_tensor = phi(output.detach())\n",
    "\n",
    "        # Replace the base activations with source activations at the intervention positions\n",
    "        result_tensor = torch.where(mode_info[1], source_activations, result_tensor)\n",
    "\n",
    "        # Rotate back to the original space and return the modified activations\n",
    "        return phi_inverse(result_tensor)\n",
    "\n",
    "# Retrieve the first MLP layer from the model\n",
    "first_layer = model.mlp.h[0].ff1  # Access the first MLPBlock's feed-forward layer \n",
    "\n",
    "# Register the forward hook to apply interventions during inference\n",
    "intervention_hook = first_layer.register_forward_hook(hook_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2934de51-e09c-41ab-abb5-89052ab096ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed training dataset for DAS from a pickle file.\n",
    "with open(\"DAS_Train.pkl\", \"rb\") as f:\n",
    "    DAS_Train = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "238cfce0-c300-423f-a6da-9ad04a3e1074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [02:34<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.891106110811234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [02:39<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 2.485404103398323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [02:34<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.5313158228248358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [02:40<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.1602864133194089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [02:35<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.06925371028482914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [02:40<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.023070329078473152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [02:35<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.012349987239576875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [02:40<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.009252700987271965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [02:35<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.007962174187414349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [02:35<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.007298748982138932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# DAS Training Process\n",
    "\n",
    "# Define hyperparameters\n",
    "epochs = 10  # Number of epochs for training\n",
    "batch_size = 6400  # Size of each training batch\n",
    "\n",
    "# Set the transformation model (phi) to training mode\n",
    "phi.train()\n",
    "\n",
    "# Freeze the weights in the classification model (since we are only training the phi model)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # Disable gradient updates for classification model parameters\n",
    "\n",
    "# Loop through the epochs\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0  # Variable to track total loss for the epoch\n",
    "\n",
    "    # Shuffle the DAS training data and create batches\n",
    "    random.shuffle(DAS_Train)\n",
    "    DAS_Train_Batches = chunk_list(DAS_Train, batch_size)  # Divide dataset into batches\n",
    "\n",
    "    # Loop through each batch in the shuffled dataset\n",
    "    for ac_batch in tqdm(DAS_Train_Batches):\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "\n",
    "        # Prepare Source Activations\n",
    "        ac_sources = extract_sources(ac_batch)  # Extract the source inputs\n",
    "        source_activations = torch.zeros(len(ac_batch), activation_dimension)  # Initialize source activations\n",
    "        source_activations = source_activations.to(device)  # Move to the appropriate device (e.g., GPU)\n",
    "\n",
    "        # For each source input, run the model to capture the rotated activations\n",
    "        for ac_source_pos in range(len(ac_sources)):\n",
    "            mode_info = [\"source\", ac_source_pos]  # Indicate that this is a source input and specify the source position\n",
    "            model(ac_sources[ac_source_pos])  # The hook function will save the rotated source activations\n",
    "\n",
    "        # Intervention Phase\n",
    "        intervention_bools = prepare_intervention_matrix(ac_batch)  # Prepare the boolean matrix indicating where to intervene\n",
    "        mode_info = [\"intervene\", intervention_bools]  # Set the mode to 'intervene' to trigger intervention in the hook\n",
    "        ac_base = extract_base(ac_batch)  # Extract the base input \n",
    "        outputs = model(ac_base)  # Run the model to apply the intervention and get outputs\n",
    "        labels = extract_labels(ac_batch)  # Extract the true labels from the batch\n",
    "        loss = criterion(outputs, labels.squeeze().long())  # Compute the loss between predicted and true labels\n",
    "        loss.backward()  # Backpropagate the loss to update the phi model\n",
    "        optimizer.step()  # Apply the gradient updates to the phi model\n",
    "        total_loss += loss.item()  # Accumulate the loss for this batch\n",
    "\n",
    "    # Print the average loss for this epoch\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(DAS_Train_Batches)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "287440fc-3f1d-4937-b68b-f577102d6fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DAS_Test.pkl\", \"rb\") as f:\n",
    "    DAS_Test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e9aeed8-2977-4143-8a25-d9481904f71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:09<00:00,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 99.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#DAS Training\n",
    "\n",
    "\n",
    "phi.eval()\n",
    "\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "DAS_Test_Batches = chunk_list(DAS_Test, batch_size)\n",
    "softm = nn.Softmax(dim=1)\n",
    "\n",
    "for ac_batch in tqdm(DAS_Test_Batches):\n",
    "\n",
    "    # Prepare Source Activations\n",
    "    ac_sources = extract_sources(ac_batch)\n",
    "    source_activations = torch.zeros(len(ac_batch), activation_dimension)\n",
    "    source_activations =source_activations.to(device)\n",
    "    for ac_source_pos in range(len(ac_sources)):\n",
    "        mode_info = [\"source\", ac_source_pos]\n",
    "        model(ac_sources[ac_source_pos])\n",
    "\n",
    "    # Intervention\n",
    "    intervention_bools = prepare_intervention_matrix(ac_batch)\n",
    "    mode_info = [\"intervene\", intervention_bools]\n",
    "    ac_base = extract_base(ac_batch)\n",
    "    outputs = model(ac_base)  # Logits\n",
    "    labels = extract_labels(ac_batch)  # True labels\n",
    "\n",
    "    # Compute predictions\n",
    "    predictions = torch.argmax(outputs, dim=1)  # Get class with highest probability\n",
    "    labels = labels.to(predictions.device)  # Ensure labels and predictions are on the same device\n",
    "\n",
    "    # Count correct predictions\n",
    "    correct = (predictions.squeeze() == labels.squeeze()).sum().item()\n",
    "    total_correct += correct\n",
    "    total_samples += labels.size(0)\n",
    "\n",
    "# Final accuracy calculation\n",
    "accuracy = total_correct / total_samples\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc13bf2-3cfa-46d6-986b-21fb6b5c1624",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
